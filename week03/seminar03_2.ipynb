{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9bc3c8b2-35fb-44c3-800e-ef9bc13a9231",
      "metadata": {
        "id": "9bc3c8b2-35fb-44c3-800e-ef9bc13a9231"
      },
      "source": [
        "# Decoding CTC output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4b923207-7a92-47f3-9f8f-1448b2ba4285",
      "metadata": {
        "id": "4b923207-7a92-47f3-9f8f-1448b2ba4285"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "\n",
        "# Load precomputed CTC output\n",
        "with open('mystery_records.pickle', 'rb') as f:\n",
        "    batch = pickle.load(f)\n",
        "\n",
        "# log probabilities of softmax layers [batch_size, T, vocab_size]\n",
        "log_probs = batch[\"log_probs\"]\n",
        "\n",
        "# Dictionary with index to character mapping\n",
        "ind2char = batch[\"ind2char\"]\n",
        "\n",
        "# Index of special EMPTY token\n",
        "EMPTY_TOK = '^'\n",
        "EMPTY_IND = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_probs.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUBmHnu_7GRF",
        "outputId": "776d6bea-a8f5-4135-e9b9-a3ec1cb5e62a"
      },
      "id": "NUBmHnu_7GRF",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 655, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind2char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74m_BPPq7KZc",
        "outputId": "0548d9ef-7fb0-465f-dca7-1d938c6f9d68"
      },
      "id": "74m_BPPq7KZc",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '^',\n",
              " 1: 'a',\n",
              " 2: 'b',\n",
              " 3: 'c',\n",
              " 4: 'd',\n",
              " 5: 'e',\n",
              " 6: 'f',\n",
              " 7: 'g',\n",
              " 8: 'h',\n",
              " 9: 'i',\n",
              " 10: 'j',\n",
              " 11: 'k',\n",
              " 12: 'l',\n",
              " 13: 'm',\n",
              " 14: 'n',\n",
              " 15: 'o',\n",
              " 16: 'p',\n",
              " 17: 'q',\n",
              " 18: 'r',\n",
              " 19: 's',\n",
              " 20: 't',\n",
              " 21: 'u',\n",
              " 22: 'v',\n",
              " 23: 'w',\n",
              " 24: 'x',\n",
              " 25: 'y',\n",
              " 26: 'z',\n",
              " 27: ' '}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "922cbf65-fbaf-48d5-8605-ea41c3f80590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "922cbf65-fbaf-48d5-8605-ea41c3f80590",
        "outputId": "ea52335b-418e-4989-fd10-effa9a853481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0) we nostrngesto love you know therols and so do i a foll commitment what i thinking of you wolden get this from any ather guy\n",
            "1)  never gona give you up never donelet you down never go arun around and deset you never gon a make you cri never gonna say good by\n"
          ]
        }
      ],
      "source": [
        "def ctc_decode(inds, ind2char):\n",
        "    decoded = []\n",
        "    last_char_ind = EMPTY_IND\n",
        "    for ind in inds:\n",
        "        if last_char_ind == ind:\n",
        "            continue\n",
        "        if ind != EMPTY_IND:\n",
        "            decoded.append(ind2char[ind])\n",
        "        last_char_ind = ind\n",
        "    return \"\".join(decoded)\n",
        "\n",
        "for i, rec in enumerate(log_probs):\n",
        "    text = ctc_decode(rec.argmax(-1).numpy(), ind2char)\n",
        "    print(f\"{i}) {text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a8c4d50-e633-4e85-8842-a6b50602b70f",
      "metadata": {
        "id": "3a8c4d50-e633-4e85-8842-a6b50602b70f"
      },
      "source": [
        "# Computing WER and CER\n",
        "Task: Implemet WER and CER metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0ca11f70-ee02-4765-b542-96186781a0b8",
      "metadata": {
        "id": "0ca11f70-ee02-4765-b542-96186781a0b8"
      },
      "outputs": [],
      "source": [
        "# library for fast quick calculation of edit distance\n",
        "import editdistance\n",
        "\n",
        "def calc_wer(target_text: str, pred_text: str):\n",
        "    if not target_text:\n",
        "        return 1\n",
        "    return editdistance.eval(target_text.split(), pred_text.split()) \\\n",
        "     / len(target_text.split())\n",
        "\n",
        "\n",
        "def calc_cer(target_text: str, pred_text: str):\n",
        "    if not target_text:\n",
        "        return 1\n",
        "    return editdistance.eval(target_text, pred_text) / len(target_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6c391511-7469-4ed8-bd26-057c4fde4717",
      "metadata": {
        "id": "6c391511-7469-4ed8-bd26-057c4fde4717"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "for target, pred, expected_wer, expected_cer in [\n",
        "    (\"if you can not measure it you can not improve it\",\n",
        "     \"if you can nt measure t yo can not i\",\n",
        "     0.454, 0.25),\n",
        "    (\"if you cant describe what you are doing as a process you dont know what youre doing\",\n",
        "     \"if you cant describe what you are doing as a process you dont know what youre doing\",\n",
        "     0.0, 0.0),\n",
        "    (\"one measurement is worth a thousand expert opinions\",\n",
        "     \"one  is worth thousand opinions\",\n",
        "     0.375, 0.392)\n",
        "]:\n",
        "    wer = calc_wer(target, pred)\n",
        "    cer = calc_cer(target, pred)\n",
        "    assert np.isclose(wer, expected_wer, atol=1e-3), f\"true: {target}, pred: {pred}, expected wer {expected_wer} != your wer {wer}\"\n",
        "    assert np.isclose(cer, expected_cer, atol=1e-3), f\"true: {target}, pred: {pred}, expected cer {expected_cer} != your cer {cer}\"\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cefd76b-66d4-4b1e-ae1d-be6b7336a160",
      "metadata": {
        "id": "7cefd76b-66d4-4b1e-ae1d-be6b7336a160"
      },
      "source": [
        "Task: come up with such a pair of target-prediction texts, so the\n",
        "1) WER > 1.0\n",
        "2) CER > WER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "11bceaaf-7b17-466b-ac17-855e4d54cf56",
      "metadata": {
        "id": "11bceaaf-7b17-466b-ac17-855e4d54cf56"
      },
      "outputs": [],
      "source": [
        "# 1) WER > 1.0\n",
        "target, prediction = \"a\" , \"a a a a a\"\n",
        "assert calc_wer(target, prediction) > 1.0\n",
        "\n",
        "# 2) CER > WER\n",
        "# your code here\n",
        "target, prediction = \"a a a\", \"bbbbbb a a\"\n",
        "assert calc_wer(target, prediction) < calc_cer(target, prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a1fb97-4853-4190-835d-31ead094679c",
      "metadata": {
        "id": "31a1fb97-4853-4190-835d-31ead094679c"
      },
      "source": [
        "# Beam search\n",
        "Task: implement beam-search on CTC outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f8e1c37a-93be-47a1-8211-9b47d0721d23",
      "metadata": {
        "id": "f8e1c37a-93be-47a1-8211-9b47d0721d23"
      },
      "outputs": [],
      "source": [
        "# Load precomputed CTC output\n",
        "with open('lj_batch.pickle', 'rb') as f:\n",
        "    batch = pickle.load(f)\n",
        "\n",
        "# log probabilities of softmax layers [batch_size, T, vocab_size]\n",
        "log_probs = batch[\"log_probs\"]\n",
        "\n",
        "# Dictionary with index to character mapping\n",
        "ind2char = batch[\"ind2char\"]\n",
        "\n",
        "true_texts = batch[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = log_probs.exp()"
      ],
      "metadata": {
        "id": "np4h7irCBJrj"
      },
      "id": "np4h7irCBJrj",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhGsyQ3VBz3u",
        "outputId": "af1a11c4-8a96-444f-ccb0-b318d004f4ad"
      },
      "id": "DhGsyQ3VBz3u",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 310, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "9ae1f264-33cb-4c4d-b959-823d07843936",
      "metadata": {
        "id": "9ae1f264-33cb-4c4d-b959-823d07843936"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "def expand_and_merge_paths(dp, next_token_probs, ind2char):\n",
        "    new_dp = defaultdict(float)\n",
        "    for ind, next_token_prob in enumerate(next_token_probs):\n",
        "        cur_char = ind2char[ind]\n",
        "        for (prefix, last_char), v in dp.items():\n",
        "            if last_char == cur_char:\n",
        "                new_prefix = prefix\n",
        "            else:\n",
        "                if cur_char == EMPTY_TOK:\n",
        "                    new_prefix = prefix\n",
        "                else:\n",
        "                    new_prefix = prefix + cur_char\n",
        "            new_dp[(new_prefix, cur_char)] += v * next_token_prob\n",
        "\n",
        "    return new_dp\n",
        "\n",
        "def truncate_paths(dp, beam_size):\n",
        "    return dict(sorted(list(dp.items()), key=lambda x: -x[1])[:beam_size])\n",
        "\n",
        "def ctc_beam_search(probs, beam_size, ind2char):\n",
        "    dp ={\n",
        "        (\"\", EMPTY_TOK): 1.0,\n",
        "    }\n",
        "    for prob in probs:\n",
        "        dp = expand_and_merge_paths(dp, prob, ind2char)\n",
        "        dp = truncate_paths(dp, beam_size)\n",
        "    dp = [(prefix, proba) for (prefix, _), proba in sorted(dp.items(), key=lambda x: -x[1])]\n",
        "    return dp\n",
        "\n",
        "bs_results = []\n",
        "for log_probs_line in log_probs:\n",
        "    bs_results.append(ctc_beam_search(log_probs_line.exp().numpy(), 100, ind2char))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "9e6d7249-aed1-4ff3-8ce2-20978320ac7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e6d7249-aed1-4ff3-8ce2-20978320ac7d",
        "outputId": "740f7dd1-d3e4-4c2a-dfb6-0c9c4636d080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True:  he would go to her and tell her all his family complications\n",
            "Argmax: he wld ge toher iand tell her all mhisan ly omblications --- (CER: 0.200)\n",
            "1) 'he wl ge to her iand tell her all hisan ly omblications' --- (CER: 0.183)\n",
            "2) 'he wl ge to her and tell her all hisan ly omblications' --- (CER: 0.167)\n",
            "3) 'he wl ge to her iand tell her all hisanly omblications' --- (CER: 0.183)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  he did not say the last as a boast but merely as an assurance to the liveryman who he saw was anxious on his account\n",
            "Argmax: he did not sad the last is a bost but mearlioves an asurance to the livery man who re saw was anxes on his account --- (CER: 0.129)\n",
            "1) 'he did not say the last is a bost but merli oves an a surance to the livery man who re saw was anxes on his account' --- (CER: 0.112)\n",
            "2) 'he did not say the last as a bost but merli oves an a surance to the livery man who re saw was anxes on his account' --- (CER: 0.103)\n",
            "3) 'he did not say the last is a bost but merli oves an a surance to the livery man who re saw was anxies on his account' --- (CER: 0.103)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  he started to conscious confusion only neither knowing where he was nor what he did\n",
            "Argmax: he started to consces confusion only neither knowing where he was nor what he did --- (CER: 0.036)\n",
            "1) 'he started to consces confusion only neither knowing where he was nor what he did' --- (CER: 0.036)\n",
            "2) 'he started to consces confusion only neither knowwing where he was nor what he did' --- (CER: 0.048)\n",
            "3) 'he started to consces confusion only neither knowing where he was nor what he did ' --- (CER: 0.048)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  i'm here because the matter is of utmost importance and brandd is the one i must see now stand aside\n",
            "Argmax: imcere because he matderacis of ut most omportanceand brand is o vammasea nhostend aside --- (CER: 0.280)\n",
            "1) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nho stend aside' --- (CER: 0.260)\n",
            "2) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nhostend aside' --- (CER: 0.270)\n",
            "3) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nhestend aside' --- (CER: 0.270)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  of course it ain't said missus bozzle\n",
            "Argmax: of coursit int said missus bozol --- (CER: 0.162)\n",
            "1) 'of cours it int said missus bozol' --- (CER: 0.135)\n",
            "2) 'of cours it int said missus bozol ' --- (CER: 0.135)\n",
            "3) 'of cours it int said missus bozal' --- (CER: 0.135)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  mister verloc was fully responsive now\n",
            "Argmax: mister volockwass fuly respons of mow --- (CER: 0.237)\n",
            "1) 'mister volockwass fuly respons of mow' --- (CER: 0.237)\n",
            "2) 'mister volockwass fuli respons of mow' --- (CER: 0.263)\n",
            "3) 'mister volockwass fuly resplons of mow' --- (CER: 0.263)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  oh what shall we do for a home\n",
            "Argmax: oh what shal we do for a whom --- (CER: 0.100)\n",
            "1) 'oh what shal we do for a whom' --- (CER: 0.100)\n",
            "2) 'ohh what shal we do for a whom' --- (CER: 0.133)\n",
            "3) 'oh what shal we do for a whom ' --- (CER: 0.100)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  line of battle was formed on the north bank of stone's river on the yankee side\n",
            "Argmax: line of battle was formed on the north bank of stones river on the yanky sidt  --- (CER: 0.063)\n",
            "1) 'wine of battle was formed on the north bank of stones river on the yanky side ' --- (CER: 0.063)\n",
            "2) 'line of battle was formed on the north bank of stones river on the yanky side ' --- (CER: 0.051)\n",
            "3) 'wine of battle was formed on the north bank of stones river on the yanky side' --- (CER: 0.051)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  from fifteen to twenty minutes will be required to bake them nicely\n",
            "Argmax: fror fifteen t teny minites will be required to bake the nicely --- (CER: 0.090)\n",
            "1) 'fror fifteengt tweny minites will be required to bake the nicely' --- (CER: 0.090)\n",
            "2) 'fror fifteen t tweny minites will be required to bake the nicely' --- (CER: 0.075)\n",
            "3) 'fror fifteengt tweny minutes will be required to bake the nicely' --- (CER: 0.075)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  whom is he going to flog now\n",
            "Argmax: whoom is agoing to flag no --- (CER: 0.214)\n",
            "1) 'whoom is agoing to flagd now' --- (CER: 0.214)\n",
            "2) 'whoom is agoing to flogd now' --- (CER: 0.179)\n",
            "3) 'whoom is agoing to flaugd now' --- (CER: 0.250)\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(true_texts)):\n",
        "    beam_search_hypos = bs_results[i][:3]\n",
        "    true_text = true_texts[i]\n",
        "    argmax_text = ctc_decode(log_probs[i].numpy().argmax(-1), ind2char)\n",
        "    print(\"True: \", true_text)\n",
        "    print(f\"Argmax: {argmax_text} --- (CER: {calc_cer(true_text, argmax_text):.3f})\")\n",
        "    for ind, (hypo, score) in enumerate(beam_search_hypos):\n",
        "        print(f\"{ind+1}) '{hypo}' --- (CER: {calc_cer(true_text, hypo):.3f})\")\n",
        "    print('-' * 100)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "HW-ASR",
      "language": "python",
      "name": "hw-asr"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}